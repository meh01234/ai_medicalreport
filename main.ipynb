{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bi0Vm1oHBrwd",
    "outputId": "7f99646f-6ce2-4ebc-f0fa-59927edfcc79"
   },
   "outputs": [],
   "source": [
    "!pip install pymupdf\n",
    "!pip install gradio\n",
    "!pip install groq --upgrade\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import fitz  # for PDF parsing\n",
    "import gradio as gr\n",
    "from groq import Groq\n",
    "import json\n",
    "import uuid  # Add this import\n",
    "import traceback  # Add this import\n",
    "\n",
    "GROQ_API_KEY = \"\"\n",
    "MODEL = 'llama3-groq-70b-8192-tool-use-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I3SjJ8fCBwSF"
   },
   "outputs": [],
   "source": [
    "class MedicalReport:\n",
    "    def __init__(self, patient_id: str, report_text: str, report_date: datetime, report_type: str):\n",
    "        self.patient_id = patient_id\n",
    "        self.report_text = report_text\n",
    "        self.report_date = report_date\n",
    "        self.report_type = report_type\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def process(self, report: MedicalReport) -> Dict:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TextPreprocessingAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"TextPreprocessingAgent\")\n",
    "\n",
    "    def process(self, report: MedicalReport) -> Dict:\n",
    "        \"\"\"Clean and normalize medical report text\"\"\"\n",
    "        text = report.report_text.lower()\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return {\"processed_text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a7NRadQiB1-T"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "class EntityExtractionAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"EntityExtractionAgent\")\n",
    "        self.groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "    def process(self, report: MedicalReport) -> Dict:\n",
    "        \"\"\"Extract medical entities from processed text\"\"\"\n",
    "        try:\n",
    "            response = self.groq_client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"You are an expert medical entity extractor.\n",
    "                        Extract medical entities from the given text.\n",
    "                        Provide a structured JSON response with these categories:\n",
    "                        - conditions: specific medical conditions\n",
    "                        - medications: any medications mentioned\n",
    "                        - tests: medical tests performed and preventive measures\n",
    "                        Ensure each category is a clean list of unique entities.\"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Extract medical entities from this text: {report.report_text}\"\n",
    "                    }\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                max_tokens=4096,\n",
    "                temperature=0.5\n",
    "            )\n",
    "\n",
    "            # Parse the response\n",
    "            entities_response = json.loads(response.choices[0].message.content)\n",
    "\n",
    "            # Clean and validate the entities\n",
    "            cleaned_entities = {\n",
    "                \"conditions\": list(set(entities_response.get(\"conditions\", []))),\n",
    "                \"medications\": list(set(entities_response.get(\"medications\", []))),\n",
    "                \"tests\": list(set(entities_response.get(\"tests\", [])))\n",
    "            }\n",
    "\n",
    "            return {\"entities\": cleaned_entities}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in entity extraction: {e}\")\n",
    "            return {\"entities\": {\n",
    "                \"conditions\": [],\n",
    "                \"medications\": [],\n",
    "                \"tests\": []\n",
    "            }}\n",
    "\n",
    "class DiagnosisAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"DiagnosisAgent\")\n",
    "        self.groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "    def process(self, report: MedicalReport, entities: Dict) -> Dict:\n",
    "        try:\n",
    "            # Flatten and filter entities\n",
    "            all_entities = []\n",
    "            for category, items in entities.items():\n",
    "                all_entities.extend([item for item in items if item])\n",
    "\n",
    "            # If no entities, return default response\n",
    "            if not all_entities:\n",
    "                return {\"diagnoses\": [\"No significant medical entities detected\"]}\n",
    "\n",
    "            # More robust diagnosis generation\n",
    "            response = self.groq_client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"You are an expert medical diagnostician.\n",
    "                        Generate a concise, structured list of potential diagnoses\n",
    "                        based on the medical entities.\n",
    "                        For each diagnosis:\n",
    "                        - Provide a clear, brief explanation\n",
    "                        - Highlight key diagnostic considerations and preventive measures\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Analyze these medical entities and provide potential diagnoses: {', '.join(all_entities)}\"\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=4096,\n",
    "                temperature=0.5\n",
    "            )\n",
    "\n",
    "            # Clean and structure diagnoses\n",
    "            diagnoses_text = response.choices[0].message.content.strip()\n",
    "            diagnoses = [\n",
    "                diagnosis.strip()\n",
    "                for diagnosis in diagnoses_text.split('\\n')\n",
    "                if diagnosis.strip() and not diagnosis.startswith('Based on')\n",
    "            ]\n",
    "\n",
    "            return {\"diagnoses\": diagnoses}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in diagnosis generation: {e}\")\n",
    "            return {\"diagnoses\": [\"Diagnosis generation failed\"]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sjgPh77VB6oj"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AlertAgent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"AlertAgent\")\n",
    "        self.critical_terms = [\n",
    "            \"urgent\", \"critical\", \"emergency\",\n",
    "            \"immediate attention\", \"severe\",\n",
    "            \"life-threatening\", \"high risk\"\n",
    "        ]\n",
    "\n",
    "    def process(self, report: MedicalReport, diagnoses: List[str]) -> Dict:\n",
    "        \"\"\"Generate alerts based on critical findings\"\"\"\n",
    "        text = report.report_text.lower()\n",
    "        alerts = []\n",
    "\n",
    "        # Generate structured alerts\n",
    "        try:\n",
    "            # Check for critical terms in the text\n",
    "            critical_alerts = [\n",
    "                f\"CRITICAL ALERT: Urgent term '{term}' detected in report\"\n",
    "                for term in self.critical_terms\n",
    "                if term in text\n",
    "            ]\n",
    "            alerts.extend(critical_alerts)\n",
    "\n",
    "            # Add structured diagnosis alerts\n",
    "            diagnosis_alerts = [\n",
    "                f\"MEDICAL ALERT: {diagnosis}\"\n",
    "                for diagnosis in diagnoses\n",
    "                if diagnosis\n",
    "            ]\n",
    "            alerts.extend(diagnosis_alerts)\n",
    "\n",
    "            # If no alerts generated, add a default alert\n",
    "            if not alerts:\n",
    "                alerts.append(\"MEDICAL REVIEW: No immediate critical findings\")\n",
    "\n",
    "            return {\"alerts\": alerts}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in alert generation: {e}\")\n",
    "            return {\"alerts\": [\"Alert generation failed\"]}\n",
    "\n",
    "class ReportAnalysisSystem:\n",
    "    def __init__(self):\n",
    "        self.agents = [\n",
    "            TextPreprocessingAgent(),\n",
    "            EntityExtractionAgent(),\n",
    "            DiagnosisAgent(),\n",
    "            AlertAgent()\n",
    "        ]\n",
    "\n",
    "    def analyze_report(self, report_text: str) -> Dict:\n",
    "        \"\"\"Orchestrate the multi-agent analysis of a medical report\"\"\"\n",
    "        try:\n",
    "            # Create initial report object\n",
    "            report = MedicalReport(\n",
    "                patient_id=str(uuid.uuid4()),  # Generate a unique ID\n",
    "                report_text=report_text,\n",
    "                report_date=datetime.now(),\n",
    "                report_type=\"PDF Report\"\n",
    "            )\n",
    "\n",
    "            # Initialize results dictionary\n",
    "            analysis_results = {}\n",
    "\n",
    "            # Process through agents\n",
    "            entity_results = None\n",
    "            diagnoses = []\n",
    "\n",
    "            for agent in self.agents:\n",
    "                if agent.name == \"TextPreprocessingAgent\":\n",
    "                    preprocessed = agent.process(report)\n",
    "                    analysis_results[agent.name] = preprocessed\n",
    "\n",
    "                elif agent.name == \"EntityExtractionAgent\":\n",
    "                    entity_results = agent.process(report)\n",
    "                    analysis_results[agent.name] = entity_results\n",
    "\n",
    "                elif agent.name == \"DiagnosisAgent\":\n",
    "                    if entity_results:\n",
    "                        diagnosis_results = agent.process(report, entity_results.get('entities', {}))\n",
    "                        analysis_results[agent.name] = diagnosis_results\n",
    "                        diagnoses = diagnosis_results.get('diagnoses', [])\n",
    "\n",
    "                elif agent.name == \"AlertAgent\":\n",
    "                    alert_results = agent.process(report, diagnoses)\n",
    "                    analysis_results[agent.name] = alert_results\n",
    "\n",
    "            # Prepare final report\n",
    "            final_report = {\n",
    "                \"patient_id\": report.patient_id,\n",
    "                \"report_date\": report.report_date.isoformat(),\n",
    "                \"report_type\": report.report_type,\n",
    "                \"analysis_results\": analysis_results\n",
    "            }\n",
    "\n",
    "            return final_report\n",
    "\n",
    "        except Exception as e:\n",
    "            error_details = {\n",
    "                \"error\": \"Analysis failed\",\n",
    "                \"details\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "            return error_details\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Enhanced PDF text extraction\"\"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_file) as doc:\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                page_text = page.get_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "\n",
    "            # Additional validation\n",
    "            if not text or len(text.strip()) < 10:\n",
    "                print(\"WARNING: Extracted PDF text is too short\")\n",
    "                return \"\"\n",
    "\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF text: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return \"\"\n",
    "\n",
    "def analyze_medical_report(pdf_file):\n",
    "    \"\"\"Comprehensive medical report analysis with error handling\"\"\"\n",
    "    try:\n",
    "        # Validate PDF file\n",
    "        if not pdf_file:\n",
    "            error_result = {\n",
    "                \"error\": \"No PDF file provided\",\n",
    "                \"details\": \"Please upload a valid PDF file\"\n",
    "            }\n",
    "            return error_result, str(error_result)\n",
    "\n",
    "        # Extract text\n",
    "        report_text = extract_text_from_pdf(pdf_file)\n",
    "\n",
    "        # Validate extracted text\n",
    "        if not report_text:\n",
    "            error_result = {\n",
    "                \"error\": \"Could not extract text from PDF\",\n",
    "                \"details\": \"The PDF may be empty or unreadable\"\n",
    "            }\n",
    "            return error_result, str(error_result)\n",
    "\n",
    "        # Analyze report\n",
    "        analysis_system = ReportAnalysisSystem()\n",
    "        results = analysis_system.analyze_report(report_text)\n",
    "\n",
    "        # Return both JSON results and error message (if any)\n",
    "        return results, results.get('error', 'Analysis completed successfully')\n",
    "\n",
    "    except Exception as e:\n",
    "        error_result = {\n",
    "            \"error\": \"Comprehensive analysis error\",\n",
    "            \"details\": str(e),\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }\n",
    "        return error_result, str(error_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "XgqNISzfCB1V",
    "outputId": "29a793ab-b226-4cb3-b27d-2fa8416ea73e"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Gradio interface with comprehensive error handling\n",
    "    demo = gr.Interface(\n",
    "        fn=analyze_medical_report,\n",
    "        inputs=gr.File(label=\"Upload PDF Medical Report\"),\n",
    "        outputs=[\n",
    "            gr.JSON(label=\"Analysis Results\"),\n",
    "            gr.Textbox(label=\"Error/Status Messages\")\n",
    "        ],\n",
    "        title=\"Medical Report Analysis System\",\n",
    "        description=\"Upload a PDF medical report for comprehensive analysis\"\n",
    "    )\n",
    "    demo.launch(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
