{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi0Vm1oHBrwd",
        "outputId": "7f99646f-6ce2-4ebc-f0fa-59927edfcc79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.24.13\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n",
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf\n",
        "!pip install gradio\n",
        "!pip install groq --upgrade\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import fitz  # for PDF parsing\n",
        "import gradio as gr\n",
        "from groq import Groq\n",
        "import json\n",
        "import uuid  # Add this import\n",
        "import traceback  # Add this import\n",
        "\n",
        "GROQ_API_KEY = \"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\"\n",
        "MODEL = 'llama3-groq-70b-8192-tool-use-preview'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I3SjJ8fCBwSF"
      },
      "outputs": [],
      "source": [
        "class MedicalReport:\n",
        "    def __init__(self, patient_id: str, report_text: str, report_date: datetime, report_type: str):\n",
        "        self.patient_id = patient_id\n",
        "        self.report_text = report_text\n",
        "        self.report_date = report_date\n",
        "        self.report_type = report_type\n",
        "\n",
        "class BaseAgent:\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "    def process(self, report: MedicalReport) -> Dict:\n",
        "        raise NotImplementedError\n",
        "\n",
        "class TextPreprocessingAgent(BaseAgent):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"TextPreprocessingAgent\")\n",
        "\n",
        "    def process(self, report: MedicalReport) -> Dict:\n",
        "        \"\"\"Clean and normalize medical report text\"\"\"\n",
        "        text = report.report_text.lower()\n",
        "        # Remove special characters\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        # Remove extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "        return {\"processed_text\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a7NRadQiB1-T"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "\n",
        "class EntityExtractionAgent(BaseAgent):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"EntityExtractionAgent\")\n",
        "        self.groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "    def process(self, report: MedicalReport) -> Dict:\n",
        "        \"\"\"Extract medical entities from processed text\"\"\"\n",
        "        try:\n",
        "            response = self.groq_client.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"\"\"You are an expert medical entity extractor.\n",
        "                        Extract medical entities from the given text.\n",
        "                        Provide a structured JSON response with these categories:\n",
        "                        - conditions: specific medical conditions\n",
        "                        - medications: any medications mentioned\n",
        "                        - tests: medical tests performed and preventive measures\n",
        "                        Ensure each category is a clean list of unique entities.\"\"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Extract medical entities from this text: {report.report_text}\"\n",
        "                    }\n",
        "                ],\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                max_tokens=4096,\n",
        "                temperature=0.5\n",
        "            )\n",
        "\n",
        "            # Parse the response\n",
        "            entities_response = json.loads(response.choices[0].message.content)\n",
        "\n",
        "            # Clean and validate the entities\n",
        "            cleaned_entities = {\n",
        "                \"conditions\": list(set(entities_response.get(\"conditions\", []))),\n",
        "                \"medications\": list(set(entities_response.get(\"medications\", []))),\n",
        "                \"tests\": list(set(entities_response.get(\"tests\", [])))\n",
        "            }\n",
        "\n",
        "            return {\"entities\": cleaned_entities}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in entity extraction: {e}\")\n",
        "            return {\"entities\": {\n",
        "                \"conditions\": [],\n",
        "                \"medications\": [],\n",
        "                \"tests\": []\n",
        "            }}\n",
        "\n",
        "class DiagnosisAgent(BaseAgent):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"DiagnosisAgent\")\n",
        "        self.groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "    def process(self, report: MedicalReport, entities: Dict) -> Dict:\n",
        "        try:\n",
        "            # Flatten and filter entities\n",
        "            all_entities = []\n",
        "            for category, items in entities.items():\n",
        "                all_entities.extend([item for item in items if item])\n",
        "\n",
        "            # If no entities, return default response\n",
        "            if not all_entities:\n",
        "                return {\"diagnoses\": [\"No significant medical entities detected\"]}\n",
        "\n",
        "            # More robust diagnosis generation\n",
        "            response = self.groq_client.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"\"\"You are an expert medical diagnostician.\n",
        "                        Generate a concise, structured list of potential diagnoses\n",
        "                        based on the medical entities.\n",
        "                        For each diagnosis:\n",
        "                        - Provide a clear, brief explanation\n",
        "                        - Highlight key diagnostic considerations and preventive measures\n",
        "                        \"\"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Analyze these medical entities and provide potential diagnoses: {', '.join(all_entities)}\"\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=4096,\n",
        "                temperature=0.5\n",
        "            )\n",
        "\n",
        "            # Clean and structure diagnoses\n",
        "            diagnoses_text = response.choices[0].message.content.strip()\n",
        "            diagnoses = [\n",
        "                diagnosis.strip()\n",
        "                for diagnosis in diagnoses_text.split('\\n')\n",
        "                if diagnosis.strip() and not diagnosis.startswith('Based on')\n",
        "            ]\n",
        "\n",
        "            return {\"diagnoses\": diagnoses}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in diagnosis generation: {e}\")\n",
        "            return {\"diagnoses\": [\"Diagnosis generation failed\"]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sjgPh77VB6oj"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AlertAgent(BaseAgent):\n",
        "    def __init__(self):\n",
        "        super().__init__(\"AlertAgent\")\n",
        "        self.critical_terms = [\n",
        "            \"urgent\", \"critical\", \"emergency\",\n",
        "            \"immediate attention\", \"severe\",\n",
        "            \"life-threatening\", \"high risk\"\n",
        "        ]\n",
        "\n",
        "    def process(self, report: MedicalReport, diagnoses: List[str]) -> Dict:\n",
        "        \"\"\"Generate alerts based on critical findings\"\"\"\n",
        "        text = report.report_text.lower()\n",
        "        alerts = []\n",
        "\n",
        "        # Generate structured alerts\n",
        "        try:\n",
        "            # Check for critical terms in the text\n",
        "            critical_alerts = [\n",
        "                f\"CRITICAL ALERT: Urgent term '{term}' detected in report\"\n",
        "                for term in self.critical_terms\n",
        "                if term in text\n",
        "            ]\n",
        "            alerts.extend(critical_alerts)\n",
        "\n",
        "            # Add structured diagnosis alerts\n",
        "            diagnosis_alerts = [\n",
        "                f\"MEDICAL ALERT: {diagnosis}\"\n",
        "                for diagnosis in diagnoses\n",
        "                if diagnosis\n",
        "            ]\n",
        "            alerts.extend(diagnosis_alerts)\n",
        "\n",
        "            # If no alerts generated, add a default alert\n",
        "            if not alerts:\n",
        "                alerts.append(\"MEDICAL REVIEW: No immediate critical findings\")\n",
        "\n",
        "            return {\"alerts\": alerts}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in alert generation: {e}\")\n",
        "            return {\"alerts\": [\"Alert generation failed\"]}\n",
        "\n",
        "class ReportAnalysisSystem:\n",
        "    def __init__(self):\n",
        "        self.agents = [\n",
        "            TextPreprocessingAgent(),\n",
        "            EntityExtractionAgent(),\n",
        "            DiagnosisAgent(),\n",
        "            AlertAgent()\n",
        "        ]\n",
        "\n",
        "    def analyze_report(self, report_text: str) -> Dict:\n",
        "        \"\"\"Orchestrate the multi-agent analysis of a medical report\"\"\"\n",
        "        try:\n",
        "            # Create initial report object\n",
        "            report = MedicalReport(\n",
        "                patient_id=str(uuid.uuid4()),  # Generate a unique ID\n",
        "                report_text=report_text,\n",
        "                report_date=datetime.now(),\n",
        "                report_type=\"PDF Report\"\n",
        "            )\n",
        "\n",
        "            # Initialize results dictionary\n",
        "            analysis_results = {}\n",
        "\n",
        "            # Process through agents\n",
        "            entity_results = None\n",
        "            diagnoses = []\n",
        "\n",
        "            for agent in self.agents:\n",
        "                if agent.name == \"TextPreprocessingAgent\":\n",
        "                    preprocessed = agent.process(report)\n",
        "                    analysis_results[agent.name] = preprocessed\n",
        "\n",
        "                elif agent.name == \"EntityExtractionAgent\":\n",
        "                    entity_results = agent.process(report)\n",
        "                    analysis_results[agent.name] = entity_results\n",
        "\n",
        "                elif agent.name == \"DiagnosisAgent\":\n",
        "                    if entity_results:\n",
        "                        diagnosis_results = agent.process(report, entity_results.get('entities', {}))\n",
        "                        analysis_results[agent.name] = diagnosis_results\n",
        "                        diagnoses = diagnosis_results.get('diagnoses', [])\n",
        "\n",
        "                elif agent.name == \"AlertAgent\":\n",
        "                    alert_results = agent.process(report, diagnoses)\n",
        "                    analysis_results[agent.name] = alert_results\n",
        "\n",
        "            # Prepare final report\n",
        "            final_report = {\n",
        "                \"patient_id\": report.patient_id,\n",
        "                \"report_date\": report.report_date.isoformat(),\n",
        "                \"report_type\": report.report_type,\n",
        "                \"analysis_results\": analysis_results\n",
        "            }\n",
        "\n",
        "            return final_report\n",
        "\n",
        "        except Exception as e:\n",
        "            error_details = {\n",
        "                \"error\": \"Analysis failed\",\n",
        "                \"details\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "            return error_details\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Enhanced PDF text extraction\"\"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_file) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                page_text = page.get_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "            # Additional validation\n",
        "            if not text or len(text.strip()) < 10:\n",
        "                print(\"WARNING: Extracted PDF text is too short\")\n",
        "                return \"\"\n",
        "\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting PDF text: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return \"\"\n",
        "\n",
        "def analyze_medical_report(pdf_file):\n",
        "    \"\"\"Comprehensive medical report analysis with error handling\"\"\"\n",
        "    try:\n",
        "        # Validate PDF file\n",
        "        if not pdf_file:\n",
        "            error_result = {\n",
        "                \"error\": \"No PDF file provided\",\n",
        "                \"details\": \"Please upload a valid PDF file\"\n",
        "            }\n",
        "            return error_result, str(error_result)\n",
        "\n",
        "        # Extract text\n",
        "        report_text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "        # Validate extracted text\n",
        "        if not report_text:\n",
        "            error_result = {\n",
        "                \"error\": \"Could not extract text from PDF\",\n",
        "                \"details\": \"The PDF may be empty or unreadable\"\n",
        "            }\n",
        "            return error_result, str(error_result)\n",
        "\n",
        "        # Analyze report\n",
        "        analysis_system = ReportAnalysisSystem()\n",
        "        results = analysis_system.analyze_report(report_text)\n",
        "\n",
        "        # Return both JSON results and error message (if any)\n",
        "        return results, results.get('error', 'Analysis completed successfully')\n",
        "\n",
        "    except Exception as e:\n",
        "        error_result = {\n",
        "            \"error\": \"Comprehensive analysis error\",\n",
        "            \"details\": str(e),\n",
        "            \"traceback\": traceback.format_exc()\n",
        "        }\n",
        "        return error_result, str(error_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "XgqNISzfCB1V",
        "outputId": "29a793ab-b226-4cb3-b27d-2fa8416ea73e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://854078236c349d1868.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://854078236c349d1868.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def main():\n",
        "    # Gradio interface with comprehensive error handling\n",
        "    demo = gr.Interface(\n",
        "        fn=analyze_medical_report,\n",
        "        inputs=gr.File(label=\"Upload PDF Medical Report\"),\n",
        "        outputs=[\n",
        "            gr.JSON(label=\"Analysis Results\"),\n",
        "            gr.Textbox(label=\"Error/Status Messages\")\n",
        "        ],\n",
        "        title=\"Medical Report Analysis System\",\n",
        "        description=\"Upload a PDF medical report for comprehensive analysis\"\n",
        "    )\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}